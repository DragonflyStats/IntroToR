\documentclass[a4paper,12pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{fancyhdr}
%\usepackage{listings}
\usepackage{framed}
\usepackage{graphicx}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.00.0.2570}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{LastRevised=Wednesday, February 23, 2011 13:24:34}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{Language=American English}

\pagestyle{fancy}
\setmarginsrb{20mm}{0mm}{20mm}{25mm}{12mm}{11mm}{0mm}{11mm}
\lhead{Dublin \texttt{R}} \rhead{September 2013}
\chead{Introduction to \texttt{R}}
%\input{tcilatex}


% http://www.norusis.com/pdf/SPC_v13.pdf
\begin{document}

\tableofcontents

Part 1a : Exploratory Data Analysis and Basic Probability

Measures and Graphical Techniques (i.e. Boxplots)
Statistical Fallacies
Part 2 : Probability Distributions

Introduction to Probability
Probability Distributions
Advanced Probability
Probability Distributions (Gambler's Ruin)
Testing the assumption of normality
Part 2a: Inference Procedures

Part 2b: More on Inference Procedures

Grubb's Outlier Test
Kolomogorov Smirnov Test


Part 3 :  Industrial Statistics

Control Charts
Statistical Process Control
Process Capability Indices
Multivariate SPC
Part 4 : Statistical Modelling of Continuous Variables

Simple Linear Regression
Multiple Linear Regression
Testing Goodness of Fit  (AIC, Likelihood)
Testing Model Assumptions and Residual Analysis
Robust Regression Models
Part 5 :  Classification Problems

Binary Logistic Regression
Multinomial Logistics Regression
Ordinary Logistic Regression
Testing Model Assumptions and Diagnostics
Part 6 :  Modelling Count Variables

The Poisson Process
Poisson Regression
Negative Binomial Regression
Zero-Inflation Models
Truncated Models
Part 7 : Reliability Analysis (Survival Models)






R and EVT

R and EVT
Overview of Proposal
Simple R Programming
vectors
integer
Character
logical
numeric
Packages
Inference procedures
Regression models and bivariate data
Tinn-R
Packages
Using and Installing packages
Installing additional packages

Overview of Proposal
how to access R
using modules
setting up projects
statistics
designing a statistical analysis
practical element focusing carrying out basic statistics and extreme value analysis on an annual maximum series
 
 
head()
length()
rbind()
cbind()

x=c(x,16)

adding a value
deleting a value
x=x[-9]

commenting #######


basic R editor
 - new script
 - updating script
 - running script
 -

Introduction to R
 - What is R
 - History of R
Simple R Programming
 - Important R functions
  - help()
  - summary()
"summary" is a generic function used to produce result summaries of the results of various model fitting functions. 
The function invokes particular methods which depend on the class of the first argument. 
  - attach()
  - data()
   - Loads specified data sets, or list the available data sets. 
  - ?
  - data.entry
  - c()
- Combine Values into a Vector or List
  - assignment operator
  - Sys.time and Sys.Date returns the system's idea of the current date with and without time. 
  - q()


mode() - storage mode of a data object( data structure)

The expression as(object, value) is the way to coerce an object to a particular class. 

vectors

vector produces a vector of the given length and mode.
as.vector, a generic, attempts to coerce its argument into a vector of mode mode (the default is to coerce to whichever mode is most convenient).
is.vector returns TRUE if x is a vector of the specified mode having no attributes other than names. It returns FALSE otherwise.  
integer
Creates or tests for objects of type "integer".
integer(length = 0)
as.integer(x, ...)
is.integer(x)
 Character
Create or test for objects of type "character".
character(length = 0)
as.character(x, ...)
is.character(x)
logical
Create or test for objects of type "logical", and the basic logical constants.
logical(length = 0)
as.logical(x, ...)
is.logical(x)
numeric
Creates or coerces objects of type "numeric". 
numeric(length = 0)
as.numeric(x, ...)
is.numeric(x)



more data structures
 - lists
   - list() Functions to construct, coerce and check for both kinds of R lists. 
 - vectors
 - dataframes
 
Packages

 - What are pacakges
- extending the program
 - where are packages to be found
 - some notable packages
 - installing packages
 - loading packages
 - updating packages
 
Probability distributions
 - Continuous: Normal / Student's 't' / Chi-square distribution
 - discrete: Binomial / Poisson / geometric distribution
Inference procedures
 - t.test
Performs one and two sample t-tests on vectors of data. 
 - prop.test
	    prop.test can be used for testing the null that the proportions (probabilities of success) in several groups are the same, or that they equal certain given values.
 - Kolmogorov-Smirnov test      [ks.test()]
Performs one or two sample Kolmogorov-Smirnov tests. 
 - Anderson Darling test        [ad.test()]
 - Grubbs test for outliers     [Grubbs.test()]
 - Dixon test for outliers
 - correlation test [cor.test()]
 - Analysis of variance. [anova()]
 

Logical functions and coercion
 - as.vector
 - is.na
 - NA is a logical constant of length 1 which contains a missing value indicator.
 - Missing value/ not available. 
Regression models and bivariate data
 - simple linear regression 
 - multiple linear regression 
 - lm()
 - lm is used to fit linear models. It can be used to carry out regression, single stratum analysis of variance and analysis of covariance 

Control Loops
 - do 
 - if 

Writing Functions

Goodness of Fit statistics
 - AIC()




Tinn-R
Tinn-R is a free open-source editor that is tailor-made for R. 

A simple way to keep output and selected graphs so they can eventually become part of a report is to copy and paste output and graphs into a Word file. Graphs can be copied and pasted as 'Windows metafiles' without loss of resolution. Text in the R output window should be pasted with a 'fixed width font' such as Courier New.

Setting up project directories

It is helpful to organize your work in project directories.
Create a directory for your project.
Copy a workspace (a .Rdata file) to the directory
You can then start R by clicking on the .Rdata file's icon
All directory references in the R session will be relative to the project directory. For example, you can read a file 'data.csv' in the directory with


 
MS4024 Week 11BC

 
http://www.r-tutor.com/elementary-statistics/hypothesis-testing/two-tailed-test-population-proportion
 

Regression more
Chi-square Tests
Binomial coefficients
Basic Probability Distributions
Continuous Probability Distributions
The Normal distribution
other distributions
Central Limit Theorem

Regression more

http://www.ats.ucla.edu/stat/R/dae/rreg.htm

Grouping, loops and conditional execution
R is an expression language in the sense that its only command type is a function or expression which returns a result. Even an assignment is an expression whose result is the value assigned, and it may be used wherever any expression may be used; in particular multiple assignments are possible.

Commands may be grouped together in braces, {expr_1; ...; expr_m}, in which case the value of the group is the result of the last expression in the group evaluated. Since such a group is also an expression it may, for example, be itself included in parentheses and used a part of an even larger expression, and so on.  


[if Statement]

Have already encountered implicit looping when using the apply
family of functions.

Conditional execution: the if statement has the form 

if (condition){ # Brackets can be omitted if only one command
expr_1 # to be carried out.
}
else {
expr_2
}

The condition must evaluate to a logical value, i.e. TRUE or
FALSE. If the condition == TRUE, expr_1 is carried out, which
can consist of a single command or multiple commands. If the
condition == FALSE, expr_2 is carried out.

[if Statement]
Can also have longer if statements:
if (condition1){
expr_1
}
else if (condition2){
expr_2
}
...
else {
expr_n
}
If condition1 == TRUE, expr_1 is executed and the checking
stops. If condition1 == FALSE, moves on to condition2 and
checks if that condition is met. If condition2 == TRUE, expr_2
is executed and checking stops. If condition2 == FALSE, moves
on to the next condition and so on until all conditions have been
checked.
The nal else is executed if none of the previous conditions have
returned a value of TRUE.

[if Statement]
Usually the logical operators &&, ||, ==, !=, >, <, >=, <= are used
as the conditions in the if statement.
The following function gives a demonstration of the use of
if... else.
comparisons1 <- function(number)
{
# if ... else
if (number != 1)
{
cat(number,"is not one\n")
}
else
{
cat(number,"is one\n")
}
}
> comparisons1(1) > comparisons1(20)
1 is one 20 is not one

[if Statement]
The following demonstrates the use of
if ... else if ... else
comparisons2 <- function(number)
{
if (number == 0)
{
cat(number,"equals 0\n")
}
else if (number > 0)
{
cat(number,"is positive\n")
}
else
{
cat(number,"is negative\n")
}
}
> comparisons2(0) > comparisons2(-15) > comparisons2(1)
0 equals 0 -15 is negative 1 is positive

[if Statement]
This function demonstrates the use of && in the condition. This
means that both conditions must be met before a value of TRUE is
returned.
comparisons3 <- function(number)
{
if ( (number > 0) && (number < 10) )
{
cat(number,"is between 0 and 10\n")
}
}
> comparisons3(-1) > comparisons3(9) > comparisons3(10)
9 is between 0 and 10

ifelse Statement
A vectorised version of the if statement is ifelse. This is useful
if you want to perform some action on every element of a vector
that satis es some condition.
The syntax is
ifelse( condition, true expr, false expr )
If condition == TRUE, the true expr is carried out. If
condition == FALSE, the false expr is carried out.
x <- rnorm(20, mean=15, sd=5)
x
[1] 23.608513 14.424667 12.306040 14.291568 18.522846 14.514071 22.004400
[8] 24.658249 11.697999 16.344976 22.110389 8.455789 19.672274 22.393680
[15] 11.449034 17.288859 14.839597 14.484774 18.636589 22.670548
ifelse(x >= 17, sqrt(x), NA)
[1] 4.858859 NA NA NA 4.303818 NA 4.690885
[8] 4.965707 NA NA 4.702169 NA 4.435344 4.732196
[15] NA 4.157987 NA NA 4.317012 4.761360



[for Loops]
Repetitive execution: for loops, while loops and repeat loops.
To loop/iterate through a certain number of repetitions a for loop
is used. The basic syntax is
for(variable_name in sequence) {
command
command
command
}
A simple example of a for loop is:
for(i in 1:5){
print(sqrt(i))
}
[1] 1
[1] 1.414214
[1] 1.732051
[1] 2
[1] 2.236068

[for Loops]
Another example is:
n <- 20
p <- 5
value <- vector(mode="numeric", length=n)
rand.nums <- matrix(rnorm(n*p), nrow=n)
for(i in 1:length(value)){
value[i] <- max(rand.nums[i,])
print(sum(value))
}
The rst four lines create variables n and p with values 20 and 5
respectively, a numeric vector called value with length 20 and a
matrix of 20*5=100 random numbers, called rand.nums, with 20
rows.
The for loop performs 20 loops and stores the maximum value
from each row of rand.nums into position i of the vector value.
The sum of the current numbers in value is also printed to the
screen.

[for Loops]
Can also have nested for loops. Indenting your code can be useful
when trying to \match" brackets.
for(variable_name1 in sequence) {
command
command
for(variable_name2 in sequence) {
command
command
command
} # ends inner for loop
} # ends outer for loop
It should be noted that variable_name2 should be di erent from
variable_name1, e.g. use i and j. Using the same name will
reset the counter each time and result in an in nite loop!!

[for Loops]
Load the function simple.nesting from Loops.R and call the
function using
simple.nesting(num.fam=5, num.child=3).
The le nest.dat will be created in your current working
directory. Open this le and explore the contents.
for loops and multiply nested for loops are generally avoided
when possible in R as they can be quite slow. We will use in
simulation examples later in the course.

[while Loops]
The while loop can be used if the number of iterations required is
not known beforehand. For example, if we want to continue
looping until a certain condition is met, a while loop is useful.
The following is the syntax for a while loop:
while (condition){
command
command
}
The loop continues while condition == TRUE.
niter <- 0
num <- sample(1:100, 1)
while(num != 20) {
num <- sample(1:100, 1)
niter <- niter + 1
}
niter

next, break, repeat Statements
The next statement can be used to discontinue one particular
iteration of any loop, i.e. this iteration is ended and the loop
\skips" to the next iteration. Useful if you want a loop to continue
even if an error is found (error checking).
The break statement completely terminates a loop. Useful if you
want a loop to end if an error is found. See the Loops.R script le
for code to exhibit the di erence between the next and break
statements.
The repeat loop uses next and break. The only way to end this
type of loop is to use the break statement. For an example, see
the Loops.R script le.

 

Chi-square Tests
Hypothesis test for count data that use the Pearson Chi-square statistic are available in R.
These include the goodness-of-fit tests and those for contingency tables. Each of these are
performed by using the chisq.test() function. 

The basic syntax for this function is (see ?chisq.test for more information): 
 
http://www.r-tutor.com/elementary-statistics/probability-distributions

A probability distribution describes how the values of a random variable is distributed. For example, the collection of all possible outcomes of a sequence of coin tossing is known to follow the binomial distribution. Whereas the means of sufficiently large samples of a data population are known to resemble the normal distribution. Since the characteristics of these theoretical distributions are well understood, they can be used to make statistical inferences on the entire data population as a whole.
In the following tutorials, we demonstrate how to compute a few well-known probability distributions that occurs frequently in statistical study. We reference them quite often in other sections.

Binomial Distribution
Poisson Distribution
Continuous Uniform Distribution
Exponential Distribution
Normal Distribution
Chi-squared Distribution
Student t Distribution
F Distribution


Binomial coefficients
' n choose k'
nk =n!k! (n-k)!

RSS Higher Certificate Module 4 Linear model
(Royal Statistical Society Professional Exams)
Advanced Data Modelling

Use Simple Linear Regression for calibration and reverse prediction,
Apply and evaluate regression diagnostics with emphasis on leverage and influence points.
Explain the Matrix formulation of the linear model
Understand multiple regression, partial correlation, polynomial regression.
Apply Analysis of Variance : multiple comparisons, two-way ANOVA, interactions
Understand analysis of covariance.
Overview of Generalized Linear Models including nonlinear regression, logistic regression and log-linear models.
1. Simple Linear Regression :

calibration, reverse prediction, regression through the origin, analysis of residuals, regression diagnostics, leverage and influence.
2. Matrix formulation of the linear model :

Multiple regression, partial correlation, polynomial regression.

Regression

Simple linear regression. Least squares estimation.
Multiple linear regression – concepts, interpretation of computer output, inference for regression coefficients using estimates and estimated standard errors from computer output.
Analysis of variance for regression models.
Calculation and interpretation of the multiple correlation coefficient (coefficient of determination).
Simple cases of transforming to linearity.
Correlation

Product-moment correlation (Pearson).
Rank correlation – Spearman’s coefficient.
Calculation and interpretation.
Design of experiments

Reasons for experimentation, causality.
Principles of replication and randomisation, completely randomised design.
Analysis of variance

One-way analysis of variance.
Inference for means and for differences in means
One-way ANOVA, multiple comparisons,
Two-way ANOVA with  interactions,
Analysis of covariance.
Generalized Linear Models

Introduction to Generalized Linear Models including nonlinear regression, logistic regression and log-linear models.
%=============================================%
Basic Probability Distributions

We look at some of the basic operations associated with probability distributions. There are a large number of probability distributions available, but we only look at a few. If you would like to know what distributions are available you can do a search using the command help.search("distribution").

Here we give details about the commands associated with the normal distribution and briefly mention the commands for other distributions. The functions for different distributions are very similar where the differences are noted below.

For this chapter it is assumed that you know how to enter data which is covered in the first chapter.

The Normal Distribution
The t Distribution
The Binomial Distribution
The Chi-Squared Distribution
The Normal Distribution

There are four functions that can be used to generate the values associated with the normal distribution. You can get a full list of them and their options using the help command:

> help(Normal)
The first function we look at it dnorm. Given a set of values it returns the height of the probability distribution at each point. If you only give the points it assumes you want to use a mean of zero and standard deviation of one. 

There are options to use different values for the mean and standard deviation, though:

> dnorm(0)
[1] 0.3989423
> dnorm(0)*sqrt(2*pi)
[1] 1
> dnorm(0,mean=4)    
[1] 0.0001338302
> dnorm(0,mean=4,sd=10)
[1] 0.03682701
>v <- c(0,1,2)
> dnorm(v)
[1] 0.39894228 0.24197072 0.05399097
> x <- seq(-20,20,by=.1)
> y <- dnorm(x) 
> plot(x,y)
> y <- dnorm(x,mean=2.5,sd=0.1) 
> plot(x,y)
The second function we examine is pnorm. Given a number or a list it computes the probability that a normally distributed random number will be less than that number. 

This function also goes by the rather ominous title of the "Cumulative Distribution Function." It accepts the same options as dnorm:

> pnorm(0)
[1] 0.5
> pnorm(1)
[1] 0.8413447
> pnorm(0,mean=2)
[1] 0.02275013
> pnorm(0,mean=2,sd=3)
[1] 0.2524925
> v <- c(0,1,2)         
> pnorm(v)
[1] 0.5000000 0.8413447 0.9772499
> x <- seq(-20,20,by=.1)
> y <- pnorm(x) 
> plot(x,y)
> y <- pnorm(x,mean=3,sd=4) 
> plot(x,y)
The next function we look at is qnorm which is the inverse of pnorm. The idea behind qnorm is that you give it a probability, and it returns the number whose cumulative distribution matches the probability. For example, if you have a normally distributed random variable with mean zero and standard deviation one, then if you give the function a probability it returns the associated Z-score:

> qnorm(0.5)
[1] 0
> qnorm(0.5,mean=1)
[1] 1
> qnorm(0.5,mean=1,sd=2)
[1] 1
> qnorm(0.5,mean=2,sd=2)
[1] 2
> qnorm(0.5,mean=2,sd=4)
[1] 2
> qnorm(0.25,mean=2,sd=2)
[1] 0.6510205
> qnorm(0.333)
[1] -0.4316442
> qnorm(0.333,sd=3)
[1] -1.294933
> qnorm(0.75,mean=5,sd=2)
[1] 6.34898
> v = c(0.1,0.3,0.75)
> qnorm(v)
[1] -1.2815516 -0.5244005  0.6744898
> x <- seq(0,1,by=.05)
> y <- qnorm(x)
> plot(x,y)
> y <- qnorm(x,mean=3,sd=2)
> plot(x,y)
> y <- qnorm(x,mean=3,sd=0.1)
> plot(x,y)
The last function we examine is the rnorm function which can generate random numbers whose distribution is normal. The argument that you give it is the number of random numbers that you want, and it has optional arguments to specify the mean and standard deviation:

> rnorm(4)
[1]  1.2387271 -0.2323259 -1.2003081 -1.6718483
> rnorm(4,mean=3)
[1] 2.633080 3.617486 2.038861 2.601933
> rnorm(4,mean=3,sd=3)
[1] 4.580556 2.974903 4.756097 6.395894
> rnorm(4,mean=3,sd=3)
[1]  3.000852  3.714180 10.032021  3.295667
> y <- rnorm(200)
> hist(y)
> y <- rnorm(200,mean=-2)
> hist(y)
> y <- rnorm(200,mean=-2,sd=4)
> hist(y)
> qqnorm(y)
> qqline(y)
The t Distribution

There are four functions that can be used to generate the values associated with the t distribution. You can get a full list of them and their options using the help command:

> help(TDist)
These commands work just like the commands for the normal distribution. One difference is that the commands assume that the values are normalized to mean zero and standard deviation one, so you have to use a little algebra to use these functions in practice. The other difference is that you have to specify the number of degrees of freedom. The commands follow the same kind of naming convention, and the names of the commands are dt, pt, qt, and rt.

A few examples are given below to show how to use the different commands. First we have the distribution function, dt:

> x <- seq(-20,20,by=.5)
> y <- dt(x,df=10)
> plot(x,y)
> y <- dt(x,df=50)
> plot(x,y)
Next we have the cumulative probability distribution function:

> pt(-3,df=10)
[1] 0.006671828
> pt(3,df=10)
[1] 0.9933282
> 1-pt(3,df=10)
[1] 0.006671828
> pt(3,df=20)
[1] 0.996462
> x = c(-3,-4,-2,-1)
> pt((mean(x)-2)/sd(x),df=20)
[1] 0.001165548
> pt((mean(x)-2)/sd(x),df=40)
[1] 0.000603064

Next we have the inverse cumulative probability distribution function:

> qt(0.05,df=10)
[1] -1.812461
> qt(0.95,df=10)
[1] 1.812461
> qt(0.05,df=20)
[1] -1.724718
> qt(0.95,df=20)
[1] 1.724718
> v <- c(0.005,.025,.05)
> qt(v,df=253)
[1] -2.595401 -1.969385 -1.650899
> qt(v,df=25)
[1] -2.787436 -2.059539 -1.708141
> 
Finally random numbers can be generated according to the t distribution:

> rt(3,df=10)
[1] 0.9440930 2.1734365 0.6785262
> rt(3,df=20)
[1]  0.1043300 -1.4682198  0.0715013
> rt(3,df=20)
[1]  0.8023832 -0.4759780 -1.0546125
The Binomial Distribution

There are four functions that can be used to generate the values associated with the binomial distribution. You can get a full list of them and their options using the help command:

> help(Binomial)
These commands work just like the commands for the normal distribution. The binomial distribution requires two extra parameters, the number of trials and the probability of success for a single trial. The commands follow the same kind of naming convention, and the names of the commands are dbinom, pbinom, qbinom, and rbinom.

A few examples are given below to show how to use the different commands. First we have the distribution function, dbinom:

> x <- seq(0,50,by=1)
> y <- dbinom(x,50,0.2)
> plot(x,y)
> y <- dbinom(x,50,0.6)
> plot(x,y)
> x <- seq(0,100,by=1)
> y <- dbinom(x,100,0.6)
> plot(x,y)
Next we have the cumulative probability distribution function:

> pbinom(24,50,0.5)
[1] 0.4438624
> pbinom(25,50,0.5)
[1] 0.5561376
> pbinom(25,51,0.5)
[1] 0.5
> pbinom(26,51,0.5)
[1] 0.610116
> pbinom(25,50,0.5)
[1] 0.5561376
> pbinom(25,50,0.25)
[1] 0.999962
> pbinom(25,500,0.25)
[1] 4.955658e-33
Next we have the inverse cumulative probability distribution function:

> qbinom(0.5,51,1/2)
[1] 25
> qbinom(0.25,51,1/2)
[1] 23
> pbinom(23,51,1/2)
[1] 0.2879247
> pbinom(22,51,1/2)
[1] 0.200531
Finally random numbers can be generated according to the binomial distribution:

> rbinom(5,100,.2) 
[1] 30 23 21 19 18
> rbinom(5,100,.7)
[1] 66 66 58 68 63
> 
The Chi-Squared Distribution

There are four functions that can be used to generate the values associated with the Chi-Squared distribution. You can get a full list of them and their options using the help command:

> help(Chisquare)
These commands work just like the commands for the normal distribution. The first difference is that it is assumed that you have normalized the value so no mean can be specified. The other difference is that you have to specify the number of degrees of freedom. The commands follow the same kind of naming convention, and the names of the commands are dchisq, pchisq, qchisq, and rchisq.

A few examples are given below to show how to use the different commands. First we have the distribution function, dchisq:

> x <- seq(-20,20,by=.5)
> y <- dchisq(x,df=10)
> plot(x,y)
> y <- dchisq(x,df=12)
> plot(x,y)
Next we have the cumulative probability distribution function:

> pchisq(2,df=10)
[1] 0.003659847
> pchisq(3,df=10)
[1] 0.01857594
> 1-pchisq(3,df=10)
[1] 0.981424
> pchisq(3,df=20)
[1] 4.097501e-06
> x = c(2,4,5,6)
> pchisq(x,df=20)
[1] 1.114255e-07 4.649808e-05 2.773521e-04 1.102488e-03
Next we have the inverse cumulative probability distribution function:

> qchisq(0.05,df=10)
[1] 3.940299
> qchisq(0.95,df=10)
[1] 18.30704
> qchisq(0.05,df=20)
[1] 10.85081
> qchisq(0.95,df=20)
[1] 31.41043
> v <- c(0.005,.025,.05)
> qchisq(v,df=253)
[1] 198.8161 210.8355 217.1713
> qchisq(v,df=25)
[1] 10.51965 13.11972 14.61141
Finally random numbers can be generated according to the Chi-Squared distribution:

> rchisq(3,df=10)
[1] 16.80075 20.28412 12.39099
> rchisq(3,df=20)
[1] 17.838878  8.591936 17.486372
> rchisq(3,df=20)
[1] 11.19279 23.86907 24.81251

Continuous Probability Distributions
 
The continuous uniform distribution is commonly used in simulation.
The Normal distribution


rnorm(n=15)                         	          	             #15 random numbers, mean  = 0 , std. deviation = 1
rnorm(n=15,mean= 17)                         	             #set the mean to 17
rnorm(n=15,mean= 17,sd=4)           	             #set the standard deviation to 4
rnorm(15,17,4)                         	          	             #argument matching : default positions
 
 
other distributions
Special mathematical functions related to the beta and gamma functions.
Usage

beta(a, b)
lbeta(a, b)

gamma(x)
lgamma(x)
psigamma(x, deriv = 0)
digamma(x)
trigamma(x)

choose(n, k)
lchoose(n, k)
factorial(x)
lfactorial(x)


 
Central Limit Theorem
Hypothesis testing and con dence interval construction are based on the Central Limit Theorem.
CLT - see Introductory Data Analysis notes by Dr. Ailish Hannigan.
Can check the CLT using a small simulation example.
We will take 10000 samples of size 5 from data with a uniform distribution and record the means.
When we plot a histogram of the means, should have a normal distribution.
 
means <- numeric(10000)
for(i in 1:10000){
means[i] <- mean(runif(5))
}
hist(means)
 

Recall the Dice experiment in week 8.
 
N=100           	          	          	             #number of loops
Avgs=numeric(N)           	             #array “Avgs” store the sample means
for( i in 1:N)
              {              Dice=floor(runif(50,min=1,max=7));              Avgs[i]=mean(Dice);
              }
Avgs           	          	          	             #print Avgs dataset to screen
 
The Central limit theorem states that.

The “Dice” distribution is a discrete uniform distribution. However

mean(Avgs)           	          	             #compute the mean. Is it roughly what we are expecting?
qqnorm(Avgs)           	          	             #draws a QQ plot that is used to check for normality.
qqline(Avgs)           	          	             #adds trend line to QQplot.
shapiro.test(Avgs)           	             #Shapiro Wilk test. Normality is assumed if p-value > 0.05.
	                                     


crime=c(761,780 ,593,715,1078,567,456,686,1206,723,261 ,326,282 ,960,489,496,463,1062,805,998,126 ,792,327 ,744,434,178,679,82,339,138,627,930,875,1074,504,635,503,418,402,1023,208,766,762,301 ,372,114,515,264,208,286,2922 )

murder=c(9,11.6 ,10.2 ,8.6 ,13.1 ,5.8 ,6.3 ,5 ,8.9 ,11.4 ,3.8 ,2.3 ,2.9 ,11.4 ,7.5 ,6.4 ,6.6 ,20.3 ,3.9 ,12.7 ,1.6 ,9.8 ,3.4 ,11.3 ,13.5 ,3 ,11.3 ,
1.7 ,3.9 ,2 ,5.3 ,8 ,10.4 ,13.3 ,6 ,8.4 ,4.6 ,6.8 ,3.9 ,10.3 ,3.4 ,10.2 ,11.9 ,3.1 ,8.3 ,3.6 ,5.2 ,4.4 ,6.9 ,3.4 ,8.5 )

pctmetro=c(41.8 ,67.4 ,44.7 ,84.7 ,96.7 ,81.8 ,95.7 ,82.7 ,93 ,67.7 ,74.7 ,43.8 ,30 ,84 ,71.6 ,54.6 ,48.5 ,75 , 96.2 , 92.8 ,35.7 ,
82.7 ,69.3 ,68.3 ,30.7 ,24 ,66.3 ,41.6 ,50.6 ,59.4 ,100 ,56 ,84.8 ,91.7 ,81.3 ,60.1 ,70 ,84.8 ,93.6 ,69.8 ,32.6 ,67.7 ,83.9 ,77.5 ,77.5 ,27 ,83 ,68.1 ,41.8 ,29.7 ,100 )

pctwhite=c(75.2 ,73.5 ,82.9 ,88.6 ,79.3 ,92.5 ,89 ,79.4 ,83.5 ,70.8 ,40.9 ,96.6 ,96.7 ,81 ,90.6 ,90.9 ,91.8 ,66.7 ,91.1 ,68.9 ,98.5 ,83.1 ,94 ,87.6 ,63.3 ,92.6 ,75.2 ,94.2 ,94.3 ,98 ,80.8 ,87.1 ,86.7 ,77.2 ,87.5 ,82.5 ,93.6 ,88.7 ,92.6 ,68.6 ,90.2 ,82.8 ,85.1 ,94.8 ,77.1 ,98.4 ,89.4 ,92.1 ,96.3 ,95.9 ,31.8 )

pcths=c(86.6 ,66.9 ,66.3 ,78.7 ,76.2 ,84.4 ,79.2 ,77.5 ,74.4 ,70.9 ,80.1 ,80.1 ,79.7 ,76.2 ,75.6 ,81.3 ,64.6 ,68.3 ,80 ,78.4 ,78.8 ,76.8 ,82.4 ,73.9 ,64.3 ,81 ,70 ,76.7 ,81.8 , 82.2 ,76.7 ,75.1 ,78.8 ,74.8 ,75.7 ,74.6 ,81.5 ,74.7 ,72 ,68.3 ,77.1 ,67.1 ,72.1 ,85.1 ,75.2 ,80.8 ,83.8 ,78.6 ,66 ,83 ,73.1 )

poverty=c(9.1 ,17.4 ,20 ,15.4 ,18.2 ,9.9 ,8.5 ,10.2 ,17.8 ,13.5 ,8 ,10.3 ,13.1 ,13.6 ,12.2 ,13.1 ,20.4 ,26.4 ,10.7 ,9.7 ,10.7 ,15.4 ,11.6 ,16.1 ,24.7 ,14.9 ,14.4 ,11.2 ,10.3 ,9.9 ,10.9 ,17.4 ,9.8 ,16.4 ,13 ,19.9 ,11.8 ,13.2 ,11.2 ,18.7 ,14.2 ,19.6 ,17.4 ,10.7 ,9.7 ,10 ,12.1 ,12.6 ,22.2 ,13.3 ,26.4 )




\newpage
%------------------------------------------%




%======================================================================================================== %
1. Starting R the first time


When running R from the computer lab, your M drive will be the working directory where your work will be saved by default. You can easily change to another directory at any time by selecting Change Dir... from the File menu. 
You can save your work at any time. Select Save Workspace from the File menu. You will usually save the workspace in the working directory. When you quit R you will be prompted to save your workspace. 
%======================================================================================================= %
2. Some things to keep in mind


Everything in R is some kind of object. Objects can have different modes (numeric, character, list, function, etc.) with different structures (scalar, vector, matrix, etc.) and different classes (data frame, linear models result, etc.). 
Almost every command you execute in R uses one or more functions. Functions are called by their name followed by a set of parentheses. If any arguments are passed to the function, they are listed within the parentheses. The parentheses must always be present whether or not there are any arguments. For example, to get a listing of all the objects in your working directory, you would use objects(). If you wanted a list of objects in another directory in your search path, you might use objects(where=3). 

Use the assignment operator to create objects. The assignment operator is the "less than" symbol followed by a hyphen ( <- ). With S-PLUS you can use the underscore for the assignment operator, but that will not work with R. Apparently the equal sign can be used, but then that will not work in S-PLUS. The best practice is to use the less than and hyphen for assignments. For example, to create an object called tmp and assign it the value 3, you would enter tmp <- 3. The equal sign (=) is mainly used for passing arguments to functions, like the last command in comment b above. 

R is case sensitive. Keep that in mind when you're naming objects or calling functions. We could create another object called Tmp that would be separate and distinct from tmp. 

If you already have an object with the name tmp and you assign something else to an object with that name, then the first object is overwritten. Be careful not to lose something you want to keep. 

Once you've created objects, you may want to get rid of them later. Use the function rm() with the object names as arguments. For example, rm(tmp). 

You can recall previous commands with the up-arrow and down-arrow keys. Once you've located the command you want, you can hit enter to execute the command as is, or you can edit the line first. This can save time, especially with complicated commands. 

Open a graphics window with the function win.graph(). 

Make use of the online help. Select HTML Help from the Help menu, click on Packages, then click on Graphics and look up win.graph. You'll find a description of all possible arguments that can be used, a full discussion on its use, and some examples of how it can be used. If you just need a reminder of what arguments can be passed to a particular function, use the args() function with the function name in the parentheses. For example, try args(win.graph) to see what arguments can be used with that function and what default values they may have. Most common functions can be found in the Base package. 

In the examples that follow, pay very close attention to all associated punctuation. Things like commas and parentheses are absolutely critical to R understanding what you want to do. If you get an error after executing a command, the first thing to do is check the syntax. That is the cause of most errors. R almost always ignores spaces, so whether you type tmp<-c(1,2,3) or tmp <- c ( 1, 2, 3), you get the same result. 
The Escape key serves as your abort button. If something goes wrong or you're suddenly seeing an endless array of numbers scrolling by, you can hit the Escape key to quit whatever you're doing and get you back to the command prompt. This does not kick you out of R altogether. 
The command line interface in R uses a red font to show your input and a blue font to show results. I've tried to duplicate that in the examples in this tutorial. 

\section{The \texttt{summary()} command}
\texttt{summary()} is a generic but very useful, function to summarize many types of \texttt{R} objects, including datasets. When used on a dataset, summary returns distributional summaries of variables in the dataset.

\section{Creating Data with \texttt{R}}

\subsection{Data Import}
It is necessary to import outside data into \texttt{R} before you start analysing it. Here we will look at some relevant issues.

\subsubsection{Microsoft XLS File}
Very often, the sample data is in MS Excel$^{\mbox{\tiny{TM}}}$ format, and needs to be imported into \texttt{R} prior to use. For this, we could use the \texttt{read.xls()} function from the \textbf{\textit{gdata}} package. The command reads from an Excel spreadsheet and returns a data frame. The following shows how to load an Excel spreadsheet named ``mydata.xls". As the package is not in the core \texttt{R} library, it has to be installed and loaded into the \texttt{R} workspace. (This spreadsheet is saved in the working directory).
\begin{verbatim}
> library(gdata)                   # load the gdata package
> help(read.xls)                   # documentation
> mydata = read.xls("mydata.xls")  # read from first sheet
\end{verbatim}

%-----------------------------------------------------------------------------------------------------%

\subsubsection{CSV File}
The sample data can be in \textit{\textbf{comma separated values}} (CSV) format. Each cell inside such data file is separated by a special character, which usually is a comma, although other characters can be used as well. ( As it is vendor neutral, CSV is more versatile).
The first row of the data file should contain the column names instead of the actual data. Here is a sample of the expected format.
\begin{verbatim}
Col1,Col2,Col3
100,a1,b1
200,a2,b2
300,a3,b3
\end{verbatim}

After we copy and paste the data above in a file named ``MyData.csv" with a text editor, we can read the data with the \texttt{read.csv()} function. (The file should be in the working directory).
\begin{verbatim}
> mydata = read.csv("MyData.csv")  # read csv file
> mydata                           # print data frame
  Col1 Col2 Col3
1  100   a1   b1
2  200   a2   b2
3  300   a3   b3
\end{verbatim}
(Remark: In various European locales, as the comma character serves as decimal point, the \texttt{read.csv2()} function should be used instead.)

\bigskip
\noindent \textbf{Exercise:} Load the GNW dataset into the \texttt{R} Environment. (We will do more work with it shortly).

\subsubsection{Data export - \texttt{write.csv()}}
The basic tool to produce output files is \texttt{write.csv()}.

The only two required arguments to \texttt{write.csv()} are ,firstly, the name of a dataset or matrix (with just a single argument) then the name (in quotations) of the file to be created.

\begin{framed}
\begin{verbatim}
> getwd()
[1] "C:/Users/Kevin/Documents"
> write.csv(iris,"iris2")
> 
\end{verbatim}
\end{framed}
%Usually, the second argument, file= will be used to specify the destination as either a character string to represent a file, or a connection (i.e. database connectivity).

%By default, character strings are surrounded by quotes by write.table(); use the quote=FALSE argument to suppress this feature. To suppress row names or column names from being written to the file, use the row.names=FALSE or col.names=FALSE arguments, respectively.

%Note that col.names=TRUE (the default) produces the same sort of headers that are read using the header=TRUE argument of read.table().

The  \texttt{sep=} argument can be used to specify a separator other than a blank space. Using sep=',' (comma separated) or sep=`\textbackslash t' (tab-separated) are two common choices.



\subsubsection{Data export - \texttt{sink()}}


The code first instructs \texttt{R} to re-direct output away from the \texttt{R} terminal to the file "output.txt" and
then the relevant output  (below the summary of the GNW data frame) which goes to the sink.
To close the sink, use
\texttt{sink()} with no arguments.

\begin{framed}
\begin{verbatim}
 sink("GNW.txt")
 summary(GNW)
sink()
\end{verbatim}
\end{framed}


While a sink is open all output will go to it, replacing what is already in the file. To append output
to a file, use the \texttt{append=TRUE} option with \texttt{sink()}. 

(Here we will use the \texttt{describe()} command from the \textbf{\textit{psych}} packages)

\begin{framed}
\begin{verbatim}
install.packages("psych")
library(psych)
 
sink("GNW.txt",append=TRUE)
describe(GNW)
sink()
\end{verbatim}
\end{framed}

\subsection{Inputting an \texttt{R} script - the \texttt{source()} command}
The \texttt{source()}function runs a previously written R script in the current session. If the filename does not include a path ( such as “C:/WorkArea”) the file is taken from the current working directory. This is a particularly useful for loading pre-written data or functions  (from  later on), and other items of code into the current session.

\begin{verbatim}
# input a few scripts
source("mypackages.R")
source("myfunctions.R")
source("mydata.R")
\end{verbatim}

\subsection{ Using the \texttt{scan()} command}
The\texttt{scan()}  function is a useful method of inputting data quickly. You can use to quickly copy and paste values into the R environment.
It is best used in the manner as described in the following example.  Create a variable “X” and use the \texttt{scan()}  function to populate it with values.
Type in a value, and then press return.
Once you have entered all the values, press return again to return to normal operation.
\begin{verbatim}
> X=scan()
1: 4
2: 5
3: 5
4: 6
5: 
Read 4 items
\end{verbatim}
For the data that has been scanned,  equivalent code that would be used to define it can be retrieved and recorded using the \texttt{edit()} command. 
\subsection{Using the \texttt{scan()} command to input character data}
Previously we have seen the \texttt{scan()} command used to quickly input numeric data. The command can also be used to input character data. The addition argument , \texttt{what=" "}, must be used.  
Create a variable “grouping” that comprises, in order,  five “A”s and then six “B”s.

\begin{verbatim}
# inputting character data

grouping = scan(what=" ")

# Enter values
# Hit return again when you have finished.

\end{verbatim}


\subsection{Spreadsheet Interface}
\texttt{R} provides a spreadsheet interface for editing the values of existing data sets.
We use the command \texttt{data.entry()} , and name of the data object as the argument.

\begin{verbatim}
> data.entry(X) # Edit the data set and exit interface
> X
\end{verbatim}


%Similarly to read.csv and read.csv2, the functions write.csv and write.csv2 are provided as wrappers to read.table, with appropriate options set to produce comma- or semicolon-separated files.

%\newpage




%We can use this approach to create a data frame :
%> data.frame(rbind(X,Y))
 % X1 X2 X3
%X  1  2  3
%Y  4  5  6

%We can then use rownames and colnames to assign meaningful names to this data frame.

%---- END OF CREATING DATA
%-------------------------------------------------------------------------------------------------------%
%----------------------------------------------------------------------------------CREATING DATA--------%

%\section{Data Entry Methods}
%\subsection{Using the \texttt{scan()} command}



%\subsection{Importing and Exporting Data}
%\subsection{The \texttt{read.csv()} command}
%\subsection{The \texttt{write.csv()} command}
%\subsection{The \texttt{sink()} command}

%-------------------------------------------------------------------------%
%\subsection{Classes of Data Objects}
%\begin{verbatim}
%class(Numvec)
%class(Charvec)
%class(A)
%class(iris)
%class(Nile)
%\end{verbatim}

%-------------------------------------------------------------------------------------------------------%
%--------------------------------------------------------------------------------------VECTORS----------%
\newpage
\section{Vectors and Sequences}
\subsection{Vectors}

%The primary data type in R is the vector. Before describing how vectors work in R, it is helpful to distinguish two ideas of vectors in order to set the correct expectations.



A vector in \texttt{R} is a container vector, a statistician's collection of data, not a mathematical vector. The \texttt{R} language is designed around the assumption that a vector is an ordered set of measurements rather than a geometrical position or a physical state. (\texttt{R} supports mathematical vector operations, but they are secondary in the design of the language.) This helps explain, for example, \texttt{R}'s otherwise inexplicable vector recycling feature.

Adding a vector of length 22 and a vector of length 45 in most languages would raise an exception; the language designers would assume the programmer has made an error and the program is now in an undefined state. However, \texttt{R} allows adding two vectors regardless of their relative lengths.

\subsubsection{Recycling}
 The elements of the shorter summand are recycled as often as necessary to create a vector the length of the longer summand. This is not attempting to add physical vectors that are incompatible for addition, but rather a syntactic convenience for manipulating sets of data. (\texttt{R} does issue a warning when adding vectors of different lengths and the length of the longer vector is not an integer multiple of the length of the shorter vector. So, for example, adding vectors of lengths 3 and 7 would cause a warning, but adding vectors of length 3 and 6 would not.)

The \texttt{R}  language has no provision for scalars, nothing like a double in C-family languages. The only way to represent a single number in a variable is to use a vector of length one. And while it is possible to iterate through vectors as one might do in a for loop in C, it is usually clearer and more efficient in \texttt{R} to operate on vectors as a whole.

\subsection{Creating Vectors}
Vectors are created using the c function. For example, \texttt{p <- c(2,3,5,7)} sets p to the vector containing the first four prime numbers.
\begin{framed}
\begin{verbatim}
p <- c(2,3,5,7)
\end{verbatim}
\end{framed}
%Vectors in R are indexed starting with 1 and matrices in are stored in column-major order. In both of these ways R resembles FORTRAN.

\begin{itemize}
\item Elements of a vector can be accessed using the square bracket operators []. So in the above example, \texttt{p[3]} is 5.

\item Vectors automatically expand when assigning to an index past the end of the vector.

\item Negative indices are legal, but they have a very different meaning than in some other languages. If x is an array in Python or Perl, x[-n] returns the nth element from the end of the vector. In \texttt{R}, x[-n] returns a copy of x with the nth element removed.
\end{itemize}

\begin{framed}
\begin{verbatim}
p <- c(2,3,5,7)
p[2]
p[-2]
\end{verbatim}
\end{framed}

\begin{verbatim}
> p <- c(2,3,5,7)
> p
[1] 2 3 5 7
> p[2]
[1] 3
> p[-2]
[1] 2 5 7
\end{verbatim}


\newpage
\section{Vectors}
 Vectors are the simplest type of object in R. There are 3 main types of vectors:
\begin{itemize}
\item  Numeric vectors
\item Character vectors
\item Logical vectors
\end{itemize}
To set up a numeric vector x consisting of 7 numbers; {10, 5, 3, 6, 21,11,41}, we use the \texttt{c()} command to “concatenate” them –i.e create a vector of individual values.
To print the contents of x, simply type “x”

\begin{framed}
\begin{verbatim}
x <- c(10, 5, 3, 6, 21,11,41) 
\end{verbatim}
\end{framed}
\begin{verbatim}
> x <- c(10, 5, 3, 6, 21,11,41) 
> x 
[1] 10 5 3 6 21 11 41
\end{verbatim}

The [1] in front of the result is the index of the first element in the vector x. (The single value variables from earlier on are simply vectors containing one element).
To access a particular element of a vector, and the position of the element enclosed in square brackets.

\textbf{(End of Edit - Move to Reserve - Vectors)}
%------------------------------------------%
\subsection{Useful Commands For Vectors}

\begin{verbatim}
Newvec = c(13,16,36,55,23,11)
\end{verbatim}
\begin{itemize}
\item \texttt{sort(Newvec)}  -  sort data set in ascending order
\item \texttt{rev(Newvec) } -  reverse the data set order
\item \texttt{rep(Newvec,n)}  -  replicate the data set $n$ times
\item \texttt{rep(Newvec,each=n)} - replicate each element of the data set $n-$times
\item \texttt{diff(Newvec)} - sequential difference of each element
\item \texttt{order(Newvec)}
\item \texttt{rank(Newvec)}
\end{itemize}


\begin{verbatim}
> Newvec = c(13,16,36,55,23,11)
>
> sort(Newvec)
[1] 11 13 16 23 36 55
> rev(Newvec)
[1] 11 23 55 36 16 13
>
> rep(Newvec,2)
 [1] 13 16 36 55 23 11 13 16 36 55 23 11
> rep(Newvec,3)
 [1] 13 16 36 55 23 11 13 16 36 55 23 11 13 16 36 55 23 11
>
> rep(Newvec,each=3)
 [1] 13 13 13 16 16 16 36 36 36 55 55 55 23 23 23 11 11 11
> diff(Newvec)
[1]   3  20  19 -32 -12
> order(Newvec)
[1] 6 1 2 5 3 4
>
> rank(Newvec)
[1] 2 3 5 6 4 1
\end{verbatim}

%------------------------------------------------------%
\subsection{Sequences}
\subsubsection{Using the colon operator}
A `count-up' or a `count-down' sequence of integers will be determined automatically. This operator is very useful and we will make use of it frequently.
\begin{framed}
\begin{verbatim}
1:20
20:1
10:20
\end{verbatim}
\end{framed}
\subsubsection{Using the \texttt{seq()} operator}
Firstly we will mimic the sequences that we have created using the colon operator.
\begin{verbatim}
seq(1,20)
seq(20,1)
\end{verbatim}




%----------------------------------------------------------------------------------------------------%
\section{Indexing and Subsetting }
\subsection{Relational and Logical Operators}

Relational operators allow for the comparison of values in vectors.
\begin{center}
\begin{tabular}{|c|c|}
  \hline
greater than &	$>$\\
less than&	$<$\\
equal to	&$==$\\
less than or equal to&	$<=$\\
greater than or equal to&	$>=$\\
not equal to	&$!=$\\
  \hline
\end{tabular}
\end{center}


Note the difference of the equality operator "==" with assignment operator "=".

\& and \&\& indicate logical AND %and $\|$ and $\|\|$ indicate logical OR.
The shorter form performs element-wise comparisons in much the same way as arithmetic operators. The longer form is appropriate for programming control-flow and typically preferred in "if" clauses.
\begin{itemize}
\item We can use relational operators to subset vectors (as well as more complex data objects such as data frames, which we will meet later).
\item We specify the  relational condition in square brackets.
\item We can construct compound relational conditions too, using logical operators
\end{itemize}
%----------------------------------%
\begin{framed}
\begin{verbatim}
> vec=1:19
> vec[vec<5]
[1] 1 2 3 4
> vec[(vec<6)|(vec>16)]
[1]  1  2  3  4  5 17 18 19
\end{verbatim}
\end{framed}

\subsection{Conditional Subsetting}
 \texttt{The Subset command}
%------------------------------------%
\subsection{Selection using the Subset Function}
The subset( ) function is the easiest way to select variables and observeration. In the following example, we select all rows that have a value of age greater than or equal to 20 or age less then 10. We keep the ID and Weight columns.

% End of relational and Logical Operators

%-----------------------------------------------------------------------------------------------------------%
%--------------------------------------------------------------------------------------DATA FRAMES----------%
\section{Data Frames}


Another way that information is stored is in data frames. This is a way to take many vectors of different types and store them in the same variable. The vectors can be of all different types. For example, a data frame may contain many lists, and each list might be a list of factors, strings, or numbers.

There are different ways to create and manipulate data frames. Most are beyond the scope of this introduction. They are only mentioned here to offer a more complete description.

\subsection{Data Frames}
Technically, a data frame in \texttt{R} is a very important type of data object;  a type of table where the typical use employs the rows as observations (or cases) and the columns as variables.
Inter alia, a data frame differs from a matrix in that it can contain character values.
Many data sets are stored as data frames.
Let us consider the following two variables; age and height.
\begin{verbatim}
> age=18:29
> age
[1] 18 19 20 21 22 23 24 25 26 27 28 29
\end{verbatim}

In similar fashion, we entered the average heights in a vector called height.
\begin{verbatim}
>height=c(76.1,77,78.1,78.2,78.8,79.7,79.9,81.1,81.2,81.8,82.8,83.5)
> height
[1] 76.1 77.0 78.1 78.2 78.8 79.7 79.9 81.1 81.2 81.8 82.8 83.5
\end{verbatim}

We will now use \texttt{R}'s \texttt{data.frame()} command to create our first data frame and store the results in the data frame "village".
\begin{framed}
\begin{verbatim}
> village=data.frame(age=age,height=height)
\end{verbatim}
\end{framed}

How do we access the data in each column? One way is to state the variable containing the data frame, followed by a dollar sign, then the name of the column we wish to access (as with Lists earlier).
For example, if we wanted to access the data in the "age" column, we would do the following:
\begin{verbatim}
 > village$age
 [1] 18 19 20 21 22 23 24 25 26 27 28 29
\end{verbatim}
The additional typing required by the "dollar sign" notation can quickly become tiresome, so R provides the ability to "attach" the variables in the dataframe to our workspace.
\begin{verbatim}
> attach(village)
\end{verbatim}

Let's re-examine our workspace. ( The \texttt{ls()} command lists all data objects in the workspace )
\begin{verbatim}
> ls()
[1] "village"
\end{verbatim}


No evidence of the variables in the workspace. However, \texttt{R} has made copies of the variables in the columns of the data frame, and most importantly, we can access them without the "dollar notation." (later)
\begin{verbatim}
> age
 [1] 18 19 20 21 22 23 24 25 26 27 28 29
> height
 [1] 76.1 77.0 78.1 78.2 78.8 79.7 79.9 81.1 81.2 81.8 82.8
[12] 83.5
\end{verbatim}

Previously we have seen \texttt{rownames()} and \texttt{colnames()} to determine the names from an existing data frame. We can use these commands to create names for a new data frame also.

%-----------------------------------------------------------------------------------------------------------%
%--------------------------------------------------------------------------------------MATRICES    ---------%

\section{Matrices}
%-------------------------%
\subsection{Matrices}
\subsubsection{Creating Matrices}
\begin{verbatim}
A=matrix(c(1,-2,0,3,0,-1),nrow=2,byrow=TRUE)
B=matrix(c(4,1,0,2,-1,3),nrow=3,byrow=TRUE)
C=matrix(c(2,1,0,-3),nrow=2,byrow=TRUE)
\end{verbatim}

\subsection{Creating a matrix}
Matrices can be created using the matrix() command.

The arguments to be supplied are
1. vector of values to be entered.
2. dimensions of the matrix, specifying either the numbers of rows or columns.
Additionally you can specify if the values are to be allocated by row or column. By default they are allocated by column.

\begin{verbatim}
Vec1 = c(1,4,5,6,4,5,5,7,9)  # 9 elements

A = matrix(Vec1,nrow=3)      #3 by 3 matrix, assigned by column.

A

#      [,1] [,2] [,3]
# [1,]    1    6    5
# [2,]    4    4    7
# [3,]    5    5    9
\end{verbatim}
%---------------------------------%


Notice how the rows and column are preceded with row and column indexes. To assign by row, we must specify it by setting the appropriate argument accordingly.

\begin{framed}
\begin{verbatim}

#3 by 3 matrix. Values assigned by row.
C= matrix(  c(1,6,7,0.6,0.5,0.3,1,2,1), ncol=3 , byrow =TRUE)

C
     [,1] [,2] [,3]
[1,]  1.0  6.0  7.0
[2,]  0.6  0.5  0.3
[3,]  1.0  2.0  1.0
\end{verbatim}
\end{framed}

%--------------------------------------------------%
\subsection{Accessing Rows and Columns}
Particular rows and columns of a data object (matrix as well as other objects such as data frames) can be accessed by specifying the row number or column number, leaving the other value blank.
\begin{framed}
\begin{verbatim}

A[1,]   # access first row of A
#[1] 1 6 5

C[,2]   # access second column of C
#[1] 6.0 0.5 2.0
\end{verbatim}
\end{framed}


Naturally - particular elements may be accessed by specifying the row number and column number


\begin{verbatim}

A[1,1]
# [1] 1

# This is not just for matrices.
# It is for all suitable data objects.

iris[,1]
iris[,1:3]
iris[2,]
iris[2,3]

mtcars[2:5,4:6]
\end{verbatim}

%----------------------------------------------------%
\subsubsection{Addition and subtractions}
For matrices, addition and subtraction works on an element-wise basis.
The first elements of the respective matrices are added, and so on.


\begin{framed}
\begin{verbatim}
A+C

#     [,1] [,2] [,3]
#[1,]  2.0 12.0 12.0
#[2,]  4.6  4.5  7.3
#[3,]  6.0  7.0 10.0

A-C

#     [,1] [,2] [,3]
#[1,]  0.0  0.0 -2.0
#[2,]  3.4  3.5  6.7
#[3,]  4.0  3.0  8.0
\end{verbatim}
\end{framed}

\subsection{Matrix Multiplication}

To multiply matrices, we require a special operator for matrices; see examples
If we just used the normal multiplication, we would get an element-wise multiplication.
This type of operation is very useful as a substitute for FOR loops on many occasions.



\begin{framed}
\begin{verbatim}
 A %*% C
#     [,1] [,2] [,3]
#[1,]  9.6 19.0 13.8
#[2,] 13.4 40.0 36.2
#[3,] 17.0 50.5 45.5

 A*C
#     [,1] [,2] [,3]
#[1,]  1.0   36 35.0
#[2,]  2.4    2  2.1
#[3,]  5.0   10  9.0
\end{verbatim}
\end{framed}


\subsubsection{Basic Matrix Calculations}

\begin{itemize}
\item[1)] Inverting a matrix

To invert a matrix we use the command solve() with no additional argument.

Remember - Not all matrices are invertible.  It the determinant of a matrix is zero, then no inverse exists.

\begin{framed}
\begin{verbatim}
> solve(C)
            [,1]      [,2]       [,3]
[1,] -0.03333333  2.666667 -0.5666667
[2,] -0.10000000 -2.000000  1.3000000
[3,]  0.23333333  1.333333 -1.0333333
\end{verbatim}
\end{framed}


We can use this same command to solve a system of linear equations Ax=b. We would specify the vector b as the additional argument.
(We will look at this matter more in the MATLAB component of the course).

\item[2)] Computing the determinant

To compute the determinant, the command is simply det()


\item[3)] Determining the dimensions

To find the dimensions of matrix A, we use the dim() command
\begin{framed}
\begin{verbatim}
\end{verbatim}
\end{framed}

\item[4)] Compute the transpose

\begin{framed}
\begin{verbatim}
det(C)
#[1] 3

dim(C) # number of rows and columns.

t(C)
     [,1] [,2] [,3]
[1,]    1  0.6    1
[2,]    6  0.5    2
[3,]    7  0.3    1

\end{verbatim}
\end{framed}
 To compute the transpose of matrix A, we use the command t().



\item[5)] Cross Products and Kronecker Product

\end{itemize}
%---------------------------------------------------%
We can compute cross products using the \texttt{crossprod()} command. 
The Kronecker product ( a very useful command in numerical computation) 
is also easily implementable using the \texttt{kronecker()} command.


\begin{framed}
\begin{verbatim}
crossprod(A,C)
kronecker(A,C)
kronecker(C,A)
\end{verbatim}
\end{framed}

%------------------------------------------------------%
\subsubsection{Diagonals and the Identity Matrix}

The \texttt{diag()} command is a very versatile function for using matrices.

It can be used to create a diagonal matrix with elements of a vector in the 
principal diagonal. For an existing matrix, it can be used to return a vector 
containing the elements of the principal diagonal.

Most importantly, if k is a scalar (i.e. single number such as 3) , 
\texttt{diag()} will create a $k \times k$ identity matrix.

\begin{framed}
\begin{verbatim}

Vec2=c(1,2,3)

diag(Vec2)     #      Constructs a diag. matrix based on Vec2

diag(A)        #     Returns diagonal elements of A as a vector

diag(3)        #     Creates a 3 x 3 identity matrix

diag(diag(A))  #     Creates the diagonal matrix D of matrix A
\end{verbatim}
\end{framed}
%----------------------------------------------%1
\subsubsection{Linear Algebra Functions}

\texttt{R} supports many import linear algebra functions such as cholesky 
decomposition, trace, rank, eigenvalues etc.

The required results may be determinable from the output of a command that 
pertains to an overall approach.

The eigenvalues and eigenvectors can be computed using the eigen() function.  
A data object known as a list is then created.

\begin{verbatim}
eigen(A)       #eigenvalues and eigenvectors

qr(A)          #returns Rank of a matrix

svd(A)
\end{verbatim}
This is a very important type of matrix analysis, and many will encounter 
it again in future modules.


%------------------------------------------------------------%
\begin{framed}
\begin{verbatim}
Y = eigen(A)
names(Y)

#   y$val are the eigenvalues of A
#   y$vec are the eigenvectors of A
\end{verbatim}
\end{framed}



%------------------------------------------------------------%
\subsubsection{More on Matrices}

Note that the following commands are often useful.

\begin{itemize}
\item \texttt{rowMeans()}
\item \texttt{rowSums()}
\item \texttt{colMeans()}
\item \texttt{colSums()}
\end{itemize}

%------------------------------------------------------------%

\subsection{Using rbind() and cbind()}
Another methods of creating a matrix is to ``bind� a number of vectors 
together, either by row or by column. 
The commands are rbind() and cbind() respectively.

\begin{framed}
\begin{verbatim}
> x1 =c(1,2) ; x2 = c(3,8)

> D= rbind(x1,x2)

> E = cbind(x1,x2)

> det(D)

[1] 2

> det(E)

[1] 2
\end{verbatim}
\end{framed}


%------------------------------------------------------------%
\subsubsection{Solving a System of Linear Equations}

To solve a system of linear equations in the form Ax=b , where A is a square matrix, 
and b is a column vector of known values, we use the solve() command to determine 
the values of the unknown vector x.

%------------------------------------------------------------%

\begin{framed}
\begin{verbatim}
b=vec2  # from before

solve(A, b)

\end{verbatim}
\end{framed}
% END OF MATRICES
%--------------------------------------------------------------------------------------------------------%
%------------------------------------------------------------------------------------------LISTS---------%


%---------------------------------------------------------%
\section{Lists}
Many data objects returned as output are structured as lists, and some knowledge about them is quite important.

An  \texttt{R} list is an object consisting of an ordered collection of objects known as its components. There is no particular need for the components to be of the same mode or type, and, for example, a list could consist of a numeric vector, a logical value, a matrix, a complex vector, a character array, a function, and so on.

Here is a simple example of how to make a list:
\begin{framed}
\begin{verbatim}
Lst <- list(name="Fred", wife="Mary", no.children=3,                   
                child.ages=c(4,7,9))
\end{verbatim}
\end{framed}

Components are always numbered and may always be referred to as such.
\begin{itemize}
\item Thus if Lst is the name of a list with 4 components, these may be individually referred to as Lst[[1]], Lst[[2]],etc.
\item If Lst[[4]] is a vector, then Lst[[4]][1] is its first entry.
\end{itemize}

\begin{framed}
\begin{verbatim}
> Lst
$name
[1] "Fred"

$wife
[1] "Mary"

$no.children
[1] 3

$child.ages
[1] 4 7 9

> Lst[[1]]
[1] "Fred"
> Lst[[4]][1]
[1] 4
\end{verbatim}
\end{framed}



The function \texttt{length(Lst)} gives the number of (top level) components that the list has.

Components of lists may also be named, and in this case the component may be referred to either by giving the component name as a character string in place of the number in double square brackets, or, more conveniently, by giving an expression of the form

\begin{verbatim}
> name$component_name
\end{verbatim}

for the same thing.

This is a very useful convention as it makes it easier to get the right component if you forget the number. This dollar sign operator is very useful , particularly when looking at the output of a complex statistical function. To find out the names assigned to a list use the command \texttt{names()}.

\begin{verbatim}
> names(Lst)
[1] "name"        "wife"        "no.children" "child.ages"
> Lst$name
[1] "Fred"
\end{verbatim}

%------------------------------%
\section{A Brief Introduction to fitting Linear Models (Lists)}

A very commonly used statistical procedure is \textbf{simple linear regression}
\begin{itemize}
\item \texttt{lm()}
\item \texttt{summary()}
\end{itemize}

\begin{framed}
\begin{verbatim}
Y <- c( )
X <- c( )

plot(X,Y)
cor(X,Y)
lm(Y~X)
\end{verbatim}
\end{framed}
%------------------------%
\begin{framed}
\begin{verbatim}
FitA =lm(Y~X)
summary(FitA)
\end{verbatim}
\end{framed}
%--------------------------------%
Let's look at this summary output in more detail, to see how it is structured. Importantly this object is structured as a list of named components.
\begin{framed}
\begin{verbatim}
names(summary(FitA))
class(summary(FitA))
mode(summary(FitA))
str(summary(FitA))
\end{verbatim}
\end{framed}

%-------------------------------%
The summary of \texttt{FitA} is a data object in it's own right. We will save it under the name \texttt{Sum.FitA} (N.B. The dot in the name has no particular meaning).
\begin{framed}
\begin{verbatim}
Sum.FitA=summary(FitA)
Sum.FitA[1]
Sum.FitA$pvalue
\end{verbatim}
\end{framed}
%------------------------------%
Suppose we wish require the $p-$value for the slope estimate only.
\begin{framed}
\begin{verbatim}
class(Sum.FitA$pvalue)
mode(Sum.FitA$pvalue)
dim(Sum.FitA$pvalue)
\end{verbatim}
\end{framed}
%-------------------------------------------------%
%--------------------------------------------------------------------------------------------------------%
%------------------------------------------------------------------------------------------APPLY FAMILY--%
\section{The \texttt{apply()} family of functions}

The "apply" family of functions keep you from having to write loops to perform 
some operation on every row or every column of a matrix or data frame, or on 
every element in a list.

\subsection{The \texttt{apply()} function}
The \texttt{apply()} function is a powerful device that operates on arrays and,
 in particular, matrices.
The \texttt{apply()} function returns a vector (or array or list of values) 
obtained by applying a specified function to either the row or columns of 
an array or matrix.
To specify use for rows or columns, use the additional argument of 1 for rows, 
and 2 for columns.
\begin{framed}
\begin{verbatim}
# create a matrix of 10 rows x 2 columns
m <- matrix(c(1:10, 11:20), nrow = 10, ncol = 2)

# mean of the rows

apply(m, 1, mean)
# [1]  6  7  8  9 10 11 12 13 14 15

# mean of the columns
apply(m, 2, mean)
#[1]  5.5 15.5
\end{verbatim}
\end{framed}

The local version of \texttt{apply()} is \texttt{lapply()}, which computes a function for each 
argument of a list, provided each argument is compatible with the function argument (e.g. that is numeric).

The \texttt{lapply()} command returns a list of the same length as a list \texttt{X}, each 
element of which is the result of applying a specified function to 
the corresponding element of X.

\subsubsection{The \texttt{sapply()} command}
A user friendly version of  \texttt{lapply()}  is  \texttt{sapply()} .The \texttt{sapply()} command  is a variant of \texttt{lapply()} , returning a matrix 
instead of a list - again of the same length as a list X, 
each element of which is the result of applying a specified function to the
 corresponding element of X.
\begin{verbatim}
> x <- list(a=1:10, b=exp(-3:3), logic=c(T,F,F,T))
>
> # compute the list mean for each list element
>
> lapply(x,mean)
$a
[1] 5.5

$b
[1] 4.535125

$logic
[1] 0.5
>
> sapply(x,mean)
       a        b    logic
5.500000 4.535125 0.500000
>
\end{verbatim}





%-------------------------------------------------------------------------------------------------------------%

R is an open-source statistical package based on the S language. It is a powerful computing tool that combines the usefulness of a statistical analysis package with that of a publication quality graphics package and a matrix-based programming language. It's easy enough to use for quick and simple tasks, yet powerful enough for the most demanding ones. The goal of this demonstration is to provide a basic introduction to using R. An R session differs from that of other statistical software. You will find it to be an interactive approach where the results from one step lead to the next. This introduction to R is necessarily limited in scope to only a handful of analyses. Once you become familiar with R and browse through some of the online help topics, you will discover tools for practically any type of analysis you need. S-PLUS is a commercial application also based on the S language. Much of R is identical to the command line useage of S-PLUS. There are differences though in some functions and their arguments so existing S-PLUS code may require some modification to run in R. 
%================================================================================================== %
Topics included in this tutorial: 
1. Starting R the first time
2. Some things to keep in mind
3. Beginning an analysis
4. Visualizing your data
%======================================================================================================== %
3. Beginning an analysis


For the remainder of this tutorial, we will be analyzing the following dataset: 
Concentration
0.3330
0.1670
0.0833
0.0416
0.0208
0.0104
0.0052
Velocity
3.636
3.636
3.236
2.666
2.114
1.466
0.866
These data are measurements of the rate or velocity of a chemical reaction for different concentrations of substrate. We are interested in fitting a model of the relationship between concentration and velocity. The first thing we need to do is enter the data. We can do this from the Commands Window, from a spreadsheet interface, or by importing an existing file. Most of this tutorial will focus on command line input so let's begin there. At the prompt, create two vectors: 
> conc <- c(0.3330, 0.1670, 0.0833, 0.0416, 0.0208, 0.0104, 0.0052)
> vel <- c(3.636, 3.636, 3.236, 2.660, 2.114, 1.466, 0.866)
We use the function c(), which stands for concatenate, to create a vector. The individual elements can be numeric, as in this example, or character, or any other mode. However, all elements in a vector must be the same mode. Note that the elements are separated by commas. The spaces between elements are included for clarity and are not required by R. 
Now, we will combine these two vectors into a single data frame: 
> df <- data.frame(conc, vel)
Let's look at the data frame to be sure we entered the data correctly. To view any object in R, simply type its name: 
> df
conc   vel
1 0.3330 3.636
2 0.1670 3.636
3 0.0833 3.236
4 0.0416 2.660
5 0.0208 2.114
6 0.0104 1.466
7 0.0052 0.866
Oops. It looks like there is an error in one of the velocity entries. The fourth one down, 2.660, should be 2.666. You could use the up-arrow to recall the command you used to create vel, make the change, and run it again. Then use the up-arrow again to recall the command you used to create df and run that one again. Let's look at another way to do it. First, we'll change just that one element in the vector vel. Individual elements in a vector are referenced in square brackets. We want to change the fourth element, so we type: 
> vel[4] <- 2.666
Take a look at vel to see that it has been changed. There are a couple ways to change elements in a data frame. Treating the data frame as a matrix, we can reference the element in the fourth row and second column like this: 
> df[4,2] <- 2.666
Note the order that the row and column are referenced: first the row, then the column. Data frames also allow us to reference individual columns by their names. This is done with the name of the data frame, followed by a dollar sign, and the name of the column. So the vel data can be referenced as df$vel. Now we can change the fourth element like this: 
> df$vel[4] <- 2.666
Note that df$vel is a vector so we only need one number in the brackets. Let's take another look at df to be sure we have it right this time. 
\begin{framed}
\begin{verbatim}
> df
conc   vel 
1 0.3330 3.636
2 0.1670 3.636
3 0.0833 3.236
4 0.0416 2.666
5 0.0208 2.114
6 0.0104 1.466
7 0.0052 0.866
\end{verbatim}
\end{framed}
Looks good! We could have created this data frame in other ways. If the data were already entered into a spreadsheet, database, or ASCII file, you could import it using the appropriate commands. Alternatively, you could create a data frame using a spreadsheet-like interface right in R. From the Edit choose Data Editor... and follow the prompts. You can use the fix() command to edit existing data frames. 
Now we're ready to do an analysis.

%======================================================================================================== %
\subsection{4. Visualizing your data}


The first thing we want to do is plot the data. You can easily get a basic plot with the following:

> plot(df$conc, df$vel)

The first vector given is the independent variable to be plotted on the X-axis, the second is the dependent variable for the Y-axis. If you execute a plotting function and there is no active graphsheet, a default graphsheet will be opened for you. If you then do another plot, the first one will be lost and the new plot will be drawn in the 
same graphics window. You can keep your first plot by opening another graphsheet by typing: 

> win.graph()

The default is a square graphsheet. You can create portrait graphsheets, landscape graphsheets, any shape you want. Check win.graph in the help files to see how. 
We're going to look at 3 different ways to analyze these data: simple linear regression, non-linear regression, and polynomial regression. 


%------------------------------------------------------------------------------------------------------%
\newpage
Using the R environment
Views R Console
Graphics Console
Script Editor Console
passing a script for compiling

Creating and Editting a script using script editor

Using R Studio Integrated Development Environment

Changing GUI options

length
ls()
getwd
setwd
head()
length()
rbind()
cbind()

basic R editor
 - new script
 - updating script
 - running script
 -
"summary" is a generic function used to produce result summaries of the results of various model fitting functions. 
The function invokes particular methods which depend on the class of the first argument. 
  - attach()
  - data()
   - Loads specified data sets, or list the available data sets. 
  - ?
  - data.entry
  - c()
- Combine Values into a Vector or List
  - assignment operator
  - Sys.time and Sys.Date returns the system's idea of the current date with and without time. 
  - q()


mode() - storage mode of a data object( data structure)

"summary" is a generic function used to produce result summaries of the results of various model fitting functions. 
The function invokes particular methods which depend on the class of the first argument. 
  - attach()
  - data()
   - Loads specified data sets, or list the available data sets. 
  - ?
  - data.entry
  - c()
- Combine Values into a Vector or List
  - assignment operator
  - Sys.time and Sys.Date returns the system's idea of the current date with and without time. 
  - q()


mode() - storage mode of a data object( data structure)





Saving your workspace
Listing objects in the workspace
Removing objects from the workspace
quitting the environment

data entry
Spreadsheet Style Interface
Vectors
Lists
Output from many important statistical functions are structured as lists.
Arrays
Matrices important in advanced computational disciplines like Machine Learning.

 
The summary function


Lists
A list in R is a rather loose objects made of a collection of other arbitary objects known as its components. 








Factors

a factor is a vector of characters or integers that are used to specify a discrete classification of the component of vectors.

logical subscripting

\end{document}
